# Input section for NGINX logs
input {
  file {
    path => "/home/mekky/Project/logs/preprocessed/nginx/output.log"  # Path to preprocessed NGINX log files
    start_position => "beginning"  # Read from the beginning only for the first time
    sincedb_path => "/home/mekky/Project/sincedb/nginx_sincedb"  # Persistent sincedb_path for NGINX logs
    type => "nginx_log"  # Set a type to differentiate logs
  }

  # Input section for MySQL logs
  file {
    path => "/home/mekky/Project/logs/preprocessed/mysql/output.log"  # Path to preprocessed MySQL log files
    start_position => "beginning"  # Read from the beginning only for the first time
    sincedb_path => "/home/mekky/Project/sincedb/mysql_sincedb"  # Persistent sincedb_path for MySQL logs
    type => "mysql_log"  # Set a type to differentiate logs
  }

  # Input section for Firewall (Syslog) logs
  file {
    path => "/home/mekky/Project/logs/preprocessed/firewall/output.log"  # Path to preprocessed firewall log files
    start_position => "beginning"  # Read from the beginning only for the first time
    sincedb_path => "/home/mekky/Project/sincedb/firewall_sincedb"  # Persistent sincedb_path for firewall logs
    type => "firewall_log"  # Set a type to differentiate logs
  }
}

# Filter section to process logs and extract useful fields
filter {
  # Grok pattern to parse NGINX logs
  if [type] == "nginx_log" {
    grok {
      match => { 
        "message" => "%{IPORHOST:client_ip} %{HTTPDATE:timestamp} %{WORD:method} %{URIPATHPARAM:request} %{NOTSPACE:http_version} %{NUMBER:status_code} %{NUMBER:response_size} %{NOTSPACE:referrer} %{GREEDYDATA:user_agent}"
      }
    }

    # Add event_type for NGINX logs
    mutate {
      add_field => { "event_type" => "%{type}" }
      rename => { "request" => "url" }
    }

    # Date filter to parse the timestamp field for NGINX logs
    date {
      match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
      target => "@timestamp"
    }

    # Remove the original message field after extraction
    mutate {
      remove_field => ["message"]
    }

    mutate {
      add_field => { 
        "formatted_message" => "%{event_type}|%{client_ip}|%{method}|%{url}|%{status_code}|%{response_size}|%{referrer}|%{user_agent}" 
      }
    }
  }

  # Grok pattern to parse MySQL logs
  if [type] == "mysql_log" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{GREEDYDATA:sql_query}" 
      }
    }

    # Add event_type for MySQL logs
    mutate {
      add_field => { "event_type" => "%{type}" }
    }

    # Date filter to parse the timestamp field for MySQL logs
    date {
      match => ["timestamp", "ISO8601"]
      target => "@timestamp"
    }

    # Remove the original message field after extraction
    mutate {
      remove_field => ["message"]
    }

    mutate {
      add_field => { 
        "formatted_message" => "%{event_type}|%{sql_query}" 
      }
    }
  }

# Grok pattern to parse firewall ICMP logs
if [type] == "firewall_log" {
  if "echo request" in [message] {
    grok {
      match => {
        "message" => "%{TIME:timestamp} IP %{IP:src_ip} > %{DATA:dst_host}: ICMP echo request, id %{INT:id}, seq %{INT:seq}, length %{INT:length}"
      }
      tag_on_failure => ["_grokparsefailure"]
    }
    mutate {
      add_field => { "icmp_type" => "request" }
    }
  } else if "echo reply" in [message] {
    grok {
      match => {
        "message" => "%{TIME:timestamp} IP %{DATA:src_host} > %{IP:dst_ip}: ICMP echo reply, id %{INT:id}, seq %{INT:seq}, length %{INT:length}"
      }
      tag_on_failure => ["_grokparsefailure"]
    }
    mutate {
      add_field => { "icmp_type" => "reply" }
    }
  }

 # Create a proper JSON structure using Ruby code
  ruby {
    code => '
      data = {
        "timestamp" => event.get("timestamp"),
        "dst_host" => event.get("dst_host") || event.get("dst_ip"),
        "id" => event.get("id"),
        "length" => event.get("length"),
        "type" => event.get("icmp_type"),
        "seq" => event.get("seq"),
        "src_ip" => event.get("src_ip") || event.get("src_host")
      }
      event.set("formatted_message", "firewall_log|" + data.to_json)
    '
  }


  # Remove unnecessary fields
  mutate {
    remove_field => ["@version", "host", "path", "message", "event", "log", "@timestamp"]
  }
}
 
}

# Output section to handle different types of logs
output {

  # Combine all types into a single output
  tcp {
    host => "192.168.1.55"
    port => 5045
    codec => line {
      format => "%{formatted_message}"
    }
  }

  # Debugging output for all logs
  stdout { codec => rubydebug }  # Debugging output
}