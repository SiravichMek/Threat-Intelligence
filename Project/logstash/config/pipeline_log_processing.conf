input {
  tcp {
    port => 5045
    type => "nginx_log"
    codec => line
  }
}

filter {

    grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:timestamp} %{HOSTNAME:hostname} %{GREEDYDATA:log_entry}"
    }
  }

    mutate {
    remove_field => ["timestamp", "hostname"]
    add_field => {
      "log" => "%{log_entry}"
    }
  }

  ruby {
    code => '
      begin
        require "net/http"
        require "uri"
        require "json"
        require "timeout"
        
        # URL encode the complete log entry
        encoded_log = URI.encode_www_form_component(event.get("message"))
        uri = URI.parse("http://127.0.0.1:8080/predict_get?log=#{encoded_log}")
        
        # Add timeout and error handling
        Timeout.timeout(5) do
          response = Net::HTTP.get_response(uri)
          if response.code == "200"
            result = JSON.parse(response.body)
            # Set individual fields for better elasticsearch mapping
            event.set("prediction", result["predicted_label"])
            event.set("confidence", result["confidence_score"])
            event.set("parsed_log", result["parsed_log"])
            event.set("prediction_details", result["prediction_details"])
          else
            event.tag("api_request_failed")
            event.set("error_response", response.body)
          end
        end
      rescue => e
        event.tag("api_request_failed")
        event.set("error", e.message)
      end
    '
  }
}

output {
  file {
    path => "C:\\Users\\N0trUe\\Desktop\\Log_Data_Test\\api_response.log"
    codec => json_lines
  }
  
  if "api_request_failed" in [tags] {
    file {
      path => "C:\\Users\\N0trUe\\Desktop\\Log_Data_Test\\failed_predictions.log"
      codec => json_lines
    }
  }
  
  stdout {
    codec => rubydebug
  }
}