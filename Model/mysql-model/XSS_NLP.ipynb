{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Natchapol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9884075655887736\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      1084\n",
      "           2       0.99      1.00      0.99      2194\n",
      "\n",
      "    accuracy                           0.99      3278\n",
      "   macro avg       0.99      0.98      0.99      3278\n",
      "weighted avg       0.99      0.99      0.99      3278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the new dataset, handling any bad lines, duplicates, and missing data\n",
    "data = pd.read_csv('modified_xss_dataset.csv', encoding='utf-8', on_bad_lines='skip').dropna().drop_duplicates()\n",
    "\n",
    "# Concatenate if you have multiple datasets to combine\n",
    "# In this example, assuming only one dataset, assign it directly\n",
    "Complete_new_data = data.reset_index(drop=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Complete_new_data['Query'], Complete_new_data['Label'], test_size=0.3, random_state=42)\n",
    "\n",
    "import re\n",
    "\n",
    "def xss_tokenizer(payload):\n",
    "    tokens = []\n",
    "    current_token = ''\n",
    "    \n",
    "    # Define XSS patterns\n",
    "    xss_patterns = [\n",
    "        r'<script[^>]*?>.*?</script>',              # <script> tags\n",
    "        r'javascript\\s*:',                          # \"javascript:\" syntax\n",
    "        r'on\\w+\\s*=',                               # Inline event handlers (e.g., \"onclick=\")\n",
    "        r'<img[^>]*?on\\w+\\s*=\\s*[\"\\'].*?[\"\\']',     # <img> tags with event handlers\n",
    "        r'<iframe[^>]*?>.*?</iframe>',              # <iframe> tags\n",
    "        r'<svg[^>]*?>.*?</svg>',                    # <svg> tags\n",
    "        r'<a[^>]*?href\\s*=\\s*[\"\\']javascript:.*?[\"\\']', # <a> tags with \"javascript:\" in href\n",
    "        r'<object.*?>.*?</object>',                 # <object> tags\n",
    "        r'<embed.*?>.*?</embed>',                   # <embed> tags\n",
    "        r'<form.*?>.*?</form>',                     # <form> tags\n",
    "        r'&#[xX]?[0-9a-fA-F]+;',                    # HTML entity encoding\n",
    "        r'alert\\s*\\(.*?\\)',                         # \"alert()\" function\n",
    "        r'<.*?alert\\(.+?\\);.*?>',                   # \"<...alert();...>\" syntax\n",
    "    ]\n",
    "\n",
    "    # Combine XSS patterns into one regex\n",
    "    combined_xss_regex = '|'.join(xss_patterns)\n",
    "    \n",
    "    # Iterate over each character in payload to create tokens\n",
    "    i = 0\n",
    "    while i < len(payload):\n",
    "        # Check for matches against XSS patterns\n",
    "        match = re.match(combined_xss_regex, payload[i:])\n",
    "        if match:\n",
    "            # If a match is found, add any current token, then add the match\n",
    "            if current_token:\n",
    "                tokens.append(current_token)\n",
    "                current_token = ''\n",
    "            tokens.append(match.group(0))\n",
    "            i += len(match.group(0))  # Move past the matched pattern\n",
    "            continue\n",
    "        \n",
    "        # Accumulate regular characters until a special character or match\n",
    "        char = payload[i]\n",
    "        if char in ['\\'', '\\\"', ';', '=', '<', '>']:\n",
    "            # If there's a current token, add it before adding the special character\n",
    "            if current_token:\n",
    "                tokens.append(current_token)\n",
    "                current_token = ''\n",
    "            tokens.append(char)\n",
    "        elif char.isspace():\n",
    "            # If space is encountered, add any current token and reset\n",
    "            if current_token:\n",
    "                tokens.append(current_token)\n",
    "                current_token = ''\n",
    "        else:\n",
    "            # Otherwise, add the character to the current token\n",
    "            current_token += char\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    # Append the final token if there's any\n",
    "    if current_token:\n",
    "        tokens.append(current_token)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Vectorization with custom tokenization and N-grams (1 to 3 grams)\n",
    "vectorizer = TfidfVectorizer(tokenizer=xss_tokenizer, ngram_range=(1, 3))\n",
    "\n",
    "# Apply TF-IDF transformation to capture n-grams and token frequencies\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Model training using Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, 'logistic_regression_xss.pkl')\n",
    "\n",
    "# Save the vectorizer as well, since it is needed to preprocess new data the same way\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer_xss.pkl')\n",
    "\n",
    "print(\"Model and vectorizer saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XSS Detection Model Accuracy with Threshold Adjustment: 60.00%\n",
      "                                               Query  Label  Prediction\n",
      "0  INSERT INTO comments (username, comment) VALUE...      2           2\n",
      "1        <img src='invalid.jpg' onerror='alert(1)'/>      2           0\n",
      "2                              <b>Welcome, user!</b>      0           0\n",
      "3  <iframe src='http://malicious-site.com'></iframe>      2           2\n",
      "4    <div onclick='alert(\"Clicked!\")'>Click me</div>      2           0\n",
      "5                   <p>This is a safe paragraph.</p>      0           0\n",
      "6       <a href='javascript:alert(1)'>Click here</a>      2           0\n",
      "7            <input type='text' value='safe input'/>      0           2\n",
      "8        <svg onload='alert(document.cookie)'></svg>      2           2\n",
      "9                        Hello, welcome to our site!      0           0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the saved model and vectorizer\n",
    "model = joblib.load('logistic_regression_xss.pkl')\n",
    "vectorizer = joblib.load('tfidf_vectorizer_xss.pkl')\n",
    "\n",
    "xss_data = {\n",
    "    'Query': [\n",
    "        \"INSERT INTO comments (username, comment) VALUES ('admin', '<script>alert('Hi')</script>')\", # XSS\n",
    "        \"<img src='invalid.jpg' onerror='alert(1)'/>\", # XSS\n",
    "        \"<b>Welcome, user!</b>\",                      # Safe HTML\n",
    "        \"<iframe src='http://malicious-site.com'></iframe>\", # XSS\n",
    "        \"<div onclick='alert(\\\"Clicked!\\\")'>Click me</div>\", # XSS\n",
    "        \"<p>This is a safe paragraph.</p>\",           # Safe HTML\n",
    "        \"<a href='javascript:alert(1)'>Click here</a>\", # XSS\n",
    "        \"<input type='text' value='safe input'/>\",    # Safe HTML\n",
    "        \"<svg onload='alert(document.cookie)'></svg>\", # XSS\n",
    "        \"Hello, welcome to our site!\",                # Plain text, safe\n",
    "    ],\n",
    "    'Label': [2, 2, 0, 2, 2, 0, 2, 0, 2, 0]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "xss_test_data = pd.DataFrame(xss_data)\n",
    "\n",
    "# Tokenize and vectorize the queries using the preloaded vectorizer\n",
    "xss_test_queries = xss_test_data['Query']\n",
    "xss_test_queries_tfidf = vectorizer.transform(xss_test_queries)\n",
    "\n",
    "# Apply the model with a probability threshold\n",
    "probability_threshold = 0.7  # Experiment with this value\n",
    "xss_predictions = (model.predict_proba(xss_test_queries_tfidf)[:, 1] >= probability_threshold).astype(int)\n",
    "\n",
    "# Adjust the predictions to match your label scheme (0 for safe, 2 for XSS)\n",
    "xss_predictions_adjusted = [2 if pred == 1 else 0 for pred in xss_predictions]\n",
    "\n",
    "# Assign predictions to DataFrame and calculate accuracy\n",
    "xss_test_data['Prediction'] = xss_predictions_adjusted\n",
    "xss_accuracy = accuracy_score(xss_test_data['Label'], xss_predictions_adjusted) * 100\n",
    "\n",
    "print(f\"XSS Detection Model Accuracy with Threshold Adjustment: {xss_accuracy:.2f}%\")\n",
    "print(xss_test_data[['Query', 'Label', 'Prediction']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
